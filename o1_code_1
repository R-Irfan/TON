import cv2
import numpy as np
import mediapipe as mp

# Load the t-shirt image with an alpha channel (transparency)
tshirt_img = cv2.imread('tshirt.png', cv2.IMREAD_UNCHANGED)

# Separate the color and alpha channels
if tshirt_img.shape[2] == 4:
    alpha_channel = tshirt_img[:, :, 3]
    rgb_channels = tshirt_img[:, :, :3]
    # Create a mask where alpha is greater than 0
    mask = alpha_channel > 0
    tshirt_img = cv2.bitwise_and(rgb_channels, rgb_channels, mask=mask.astype(np.uint8))
else:
    mask = np.ones(tshirt_img.shape[:2], dtype=np.uint8) * 255

# Define key points on the t-shirt image (manually)
tshirt_points = {
    'left_shoulder': (x1, y1),
    'right_shoulder': (x2, y2),
    'left_elbow': (x3, y3),
    'right_elbow': (x4, y4),
    'left_hip': (x5, y5),
    'right_hip': (x6, y6),
    # Add more points along the arms and torso as needed
}

# Convert points to a NumPy array
src_points = np.array(list(tshirt_points.values()), dtype=np.float32)

# Initialize MediaPipe Pose
mp_pose = mp.solutions.pose

# Start the webcam feed
cap = cv2.VideoCapture(0)

with mp_pose.Pose(min_detection_confidence=0.5,
                  min_tracking_confidence=0.5) as pose:
    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            print("Failed to capture image")
            break

        # Flip and convert the image to RGB
        frame = cv2.flip(frame, 1)
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Process the image and find pose landmarks
        results = pose.process(image)

        # Convert the image color back for rendering
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        if results.pose_landmarks:
            # Extract landmark points
            landmarks = results.pose_landmarks.landmark

            # Get image dimensions
            img_h, img_w = image.shape[:2]

            # Define destination points (key points on the person)
            dst_points = {
                'left_shoulder': (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * img_w,
                                  landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * img_h),
                'right_shoulder': (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * img_w,
                                   landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * img_h),
                'left_elbow': (landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].x * img_w,
                               landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].y * img_h),
                'right_elbow': (landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].x * img_w,
                                landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].y * img_h),
                'left_hip': (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * img_w,
                             landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * img_h),
                'right_hip': (landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x * img_w,
                              landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y * img_h),
                # Add more points as defined in tshirt_points
            }

            # Convert destination points to NumPy array
            dst_points_array = np.array(list(dst_points.values()), dtype=np.float32)

            # Create a bounding rectangle around the source points
            rect = cv2.boundingRect(src_points)

            # Subdivide the bounding rectangle into triangles
            subdiv = cv2.Subdiv2D(rect)
            for p in src_points:
                subdiv.insert((float(p[0]), float(p[1])))

            # Get the list of triangles
            triangles = subdiv.getTriangleList()
            triangles = np.array(triangles, dtype=np.float32)

            # Function to find the index of a point
            def find_index(points, coord):
                for i, point in enumerate(points):
                    if np.allclose(point, coord):
                        return i
                return -1

            # List to hold triangle indices
            triangle_indices = []

            for t in triangles:
                pts = [(t[0], t[1]), (t[2], t[3]), (t[4], t[5])]
                idx = []
                for pt in pts:
                    index = find_index(src_points, np.array(pt))
                    if index != -1:
                        idx.append(index)
                if len(idx) == 3:
                    triangle_indices.append(idx)

            # Initialize output image
            output = np.zeros_like(image)

            # Function to warp a triangle
            def warp_triangle(img1, img2, t1, t2):
                # Find bounding rectangles for each triangle
                r1 = cv2.boundingRect(np.float32([t1]))
                r2 = cv2.boundingRect(np.float32([t2]))
                
                x1, y1, w1, h1 = r1
                x2, y2, w2, h2 = r2
                
                # Clip the rectangles to the image boundaries
                x1_end = min(x1 + w1, img1.shape[1])
                y1_end = min(y1 + h1, img1.shape[0])
                w1 = x1_end - x1
                h1 = y1_end - y1

                x2_end = min(x2 + w2, img2.shape[1])
                y2_end = min(y2 + h2, img2.shape[0])
                w2 = x2_end - x2
                h2 = y2_end - y2

                # Offset points by the top-left corner of the respective rectangles
                t1_rect = []
                t2_rect = []
                t2_rect_int = []

                for i in range(3):
                    t1_rect.append(((t1[i][0] - x1), (t1[i][1] - y1)))
                    t2_rect.append(((t2[i][0] - x2), (t2[i][1] - y2)))
                    t2_rect_int.append((int(t2[i][0] - x2), int(t2[i][1] - y2)))

                # Create mask by filling the triangle
                mask = np.zeros((h2, w2), dtype=np.float32)
                cv2.fillConvexPoly(mask, np.int32(t2_rect_int), 1.0, 16, 0)

                # Extract the patches from the images
                img1_rect = img1[y1:y1_end, x1:x1_end]
                img2_rect = img2[y2:y2_end, x2:x2_end]

                # Check if the sizes match
                if img1_rect.shape[0] == 0 or img1_rect.shape[1] == 0:
                    return
                if img2_rect.shape[0] == 0 or img2_rect.shape[1] == 0:
                    return

                # Warp the patch from img1 to img2
                size = (w2, h2)
                warp_mat = cv2.getAffineTransform(np.float32(t1_rect), np.float32(t2_rect))
                img1_rect_warped = cv2.warpAffine(img1_rect, warp_mat, size, None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)

                # Apply the mask to the warped patch
                img1_rect_warped = img1_rect_warped * mask[:, :, np.newaxis]

                # Blend the warped patch into the destination image
                img2_rect = img2_rect * (1.0 - mask[:, :, np.newaxis])
                img2_rect = img2_rect + img1_rect_warped

                # Place the blended patch back into the image
                img2[y2:y2_end, x2:x2_end] = img2_rect

            # Warp each triangle
            for idx in triangle_indices:
                t1 = [src_points[idx[0]], src_points[idx[1]], src_points[idx[2]]]
                t2 = [dst_points_array[idx[0]], dst_points_array[idx[1]], dst_points_array[idx[2]]]

                warp_triangle(tshirt_img, output, t1, t2)

            # Create a mask from the warped t-shirt image
            gray_output = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)
            _, mask = cv2.threshold(gray_output, 1, 255, cv2.THRESH_BINARY)
            mask_inv = cv2.bitwise_not(mask)

            # Black-out the area of the t-shirt in the frame
            img_bg = cv2.bitwise_and(image, image, mask=mask_inv)

            # Extract the t-shirt region from the warped image
            tshirt_fg = cv2.bitwise_and(output, output, mask=mask)

            # Combine the background and the t-shirt foreground
            combined = cv2.add(img_bg, tshirt_fg)

            # Display the final output
            cv2.imshow('Virtual Try-On', combined)

        else:
            # No landmarks detected; display the frame
            cv2.imshow('Virtual Try-On', image)

        # Exit on pressing 'ESC'
        if cv2.waitKey(5) & 0xFF == 27:
            break

# Release resources
cap.release()
cv2.destroyAllWindows()
