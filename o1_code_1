import cv2
import numpy as np
import mediapipe as mp

# Load the t-shirt image with an alpha channel (transparency)
tshirt_img = cv2.imread('tshirt.png', cv2.IMREAD_UNCHANGED)

# Separate the color and alpha channels
if tshirt_img.shape[2] == 4:
    alpha_channel = tshirt_img[:, :, 3]
    rgb_channels = tshirt_img[:, :, :3]
    # Create a mask where alpha is greater than 0
    mask = alpha_channel > 0
    tshirt_img = cv2.bitwise_and(rgb_channels, rgb_channels, mask=mask.astype(np.uint8))
else:
    mask = np.ones(tshirt_img.shape[:2], dtype=np.uint8) * 255

# Get t-shirt image dimensions
tshirt_height, tshirt_width = tshirt_img.shape[:2]

# Define key points on the t-shirt image (manually)
tshirt_points = {
    'left_shoulder': (int(0.3 * tshirt_width), int(0.2 * tshirt_height)),
    'right_shoulder': (int(0.7 * tshirt_width), int(0.2 * tshirt_height)),
    'left_elbow': (int(0.2 * tshirt_width), int(0.5 * tshirt_height)),
    'right_elbow': (int(0.8 * tshirt_width), int(0.5 * tshirt_height)),
    'left_hip': (int(0.3 * tshirt_width), int(0.8 * tshirt_height)),
    'right_hip': (int(0.7 * tshirt_width), int(0.8 * tshirt_height)),
    # Add more points along the arms and torso as needed
}

# Convert points to a NumPy array
src_points = np.array(list(tshirt_points.values()), dtype=np.float32)

# Initialize MediaPipe Pose
mp_pose = mp.solutions.pose

# Start the webcam feed
cap = cv2.VideoCapture(0)

with mp_pose.Pose(min_detection_confidence=0.5,
                  min_tracking_confidence=0.5) as pose:
    while cap.isOpened():
        success, frame = cap.read()
        if not success:
            print("Failed to capture image")
            break

        # Flip and convert the image to RGB
        frame = cv2.flip(frame, 1)
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Process the image and find pose landmarks
        results = pose.process(image)

        # Convert the image color back for rendering
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        if results.pose_landmarks:
            # Extract landmark points
            landmarks = results.pose_landmarks.landmark

            # Get image dimensions
            img_h, img_w = image.shape[:2]

            # Define destination points (key points on the person)
            dst_points = {
                'left_shoulder': (landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * img_w,
                                  landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * img_h),
                'right_shoulder': (landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * img_w,
                                   landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * img_h),
                'left_elbow': (landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].x * img_w,
                               landmarks[mp_pose.PoseLandmark.LEFT_ELBOW].y * img_h),
                'right_elbow': (landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].x * img_w,
                                landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW].y * img_h),
                'left_hip': (landmarks[mp_pose.PoseLandmark.LEFT_HIP].x * img_w,
                             landmarks[mp_pose.PoseLandmark.LEFT_HIP].y * img_h),
                'right_hip': (landmarks[mp_pose.PoseLandmark.RIGHT_HIP].x * img_w,
                              landmarks[mp_pose.PoseLandmark.RIGHT_HIP].y * img_h),
                # Add more points as defined in tshirt_points
            }

            # Convert destination points to NumPy array
            dst_points_array = np.array(list(dst_points.values()), dtype=np.float32)

            # Create a bounding rectangle around the source points
            rect = cv2.boundingRect(src_points)

            # Subdivide the bounding rectangle into triangles
            subdiv = cv2.Subdiv2D(rect)
            for p in src_points:
                point = (float(p[0]), float(p[1]))
                subdiv.insert(point)

            # Get the list of triangles
            triangles = subdiv.getTriangleList()
            triangles = np.array(triangles, dtype=np.float32)

            # Function to find the index of a point
            def find_index(points, coord):
                for i, point in enumerate(points):
                    if np.allclose(point, coord):
                        return i
                return -1

            # List to hold triangle indices
            triangle_indices = []

            for t in triangles:
                pts = [(t[0], t[1]), (t[2], t[3]), (t[4], t[5])]
                idx = []
                for pt in pts:
                    index = find_index(src_points, np.array(pt))
                    if index != -1:
                        idx.append(index)
                if len(idx) == 3:
                    triangle_indices.append(idx)

            # Initialize output image
            output = np.zeros_like(image)

            # Function to warp a triangle
            def warp_triangle(img1, img2, t1, t2):
                # Find bounding rectangles for each triangle
                r1 = cv2.boundingRect(np.float32([t1]))
                r2 = cv2.boundingRect(np.float32([t2]))

                # Offset points by the top-left corner of the respective rectangles
                t1_rect = []
                t2_rect = []
                t2_rect_int = []

                for i in range(3):
                    t1_rect.append(((t1[i][0] - r1[0]), (t1[i][1] - r1[1])))
                    t2_rect.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))
                    t2_rect_int.append((int(t2[i][0] - r2[0]), int(t2[i][1] - r2[1])))

                # Create mask by filling the triangle
                mask = np.zeros((r2[3], r2[2], 3), dtype=np.float32)
                cv2.fillConvexPoly(mask, np.int32(t2_rect_int), (1.0, 1.0, 1.0), 16, 0)

                # Extract the patch from the t-shirt image
                img1_rect = img1[r1[1]:r1[1]+r1[3], r1[0]:r1[0]+r1[2]]

                # Warp the patch
                size = (r2[2], r2[3])
                warp_mat = cv2.getAffineTransform(np.float32(t1_rect), np.float32(t2_rect))
                img2_rect = cv2.warpAffine(img1_rect, warp_mat, size, None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)

                # Apply the mask to the warped patch
                img2_rect = img2_rect * mask

                # Copy the warped patch into the output image
                img2_area = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]]
                img2_area = img2_area * (1 - mask)
                img2_area = img2_area + img2_rect

                img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2_area

            # Warp each triangle
            for idx in triangle_indices:
                t1 = [src_points[idx[0]], src_points[idx[1]], src_points[idx[2]]]
                t2 = [dst_points_array[idx[0]], dst_points_array[idx[1]], dst_points_array[idx[2]]]

                warp_triangle(tshirt_img, output, t1, t2)

            # Create a mask from the warped t-shirt image
            gray_output = cv2.cvtColor(output, cv2.COLOR_BGR2GRAY)
            _, mask = cv2.threshold(gray_output, 1, 255, cv2.THRESH_BINARY)
            mask_inv = cv2.bitwise_not(mask)

            # Black-out the area of the t-shirt in the frame
            img_bg = cv2.bitwise_and(image, image, mask=mask_inv)

            # Extract the t-shirt region from the warped image
            tshirt_fg = cv2.bitwise_and(output, output, mask=mask)

            # Combine the background and the t-shirt foreground
            combined = cv2.add(img_bg, tshirt_fg)

            # Display the final output
            cv2.imshow('Virtual Try-On', combined)

        else:
            # No landmarks detected; display the frame
            cv2.imshow('Virtual Try-On', image)

        # Exit on pressing 'ESC'
        if cv2.waitKey(5) & 0xFF == 27:
            break

# Release resources
cap.release()
cv2.destroyAllWindows()
